{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:38:22.150538: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 15:38:23.233317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 15:38:23.233617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-13 15:38:23.233623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import keras.utils as image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CNN model...\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 100, 100, 32  896         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 98, 98, 32)   9248        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 98, 98, 32)  128         ['conv2d_15[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 49, 49, 32)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 49, 49, 32)   0           ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 49, 49, 64)   18496       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 47, 47, 64)   36928       ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 47, 47, 64)  256         ['conv2d_17[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 23, 23, 64)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 23, 23, 64)   0           ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 23, 23, 128)  73856       ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 21, 21, 128)  147584      ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 21, 21, 128)  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 10, 10, 128)  0          ['batch_normalization_10[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 10, 10, 128)  0           ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 256)    295168      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 4, 4, 256)   0           ['batch_normalization_11[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4096)         0           ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 4096)         0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " digit1 (Dense)                 (None, 36)           147492      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " digit2 (Dense)                 (None, 36)           147492      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 879,080\n",
      "Trainable params: 878,120\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n",
      "(20000, 100, 100, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:43:37.552432: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1920000000 exceeds 10% of free system memory.\n",
      "2022-12-13 15:43:38.659064: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1920000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "  2/160 [..............................] - ETA: 8s - loss: 12.4708 - digit1_loss: 6.3800 - digit2_loss: 6.0909 - digit1_accuracy: 0.0600 - digit2_accuracy: 0.0400      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:43:39.907207: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_2/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 10s 59ms/step - loss: 8.2467 - digit1_loss: 4.1056 - digit2_loss: 4.1410 - digit1_accuracy: 0.0746 - digit2_accuracy: 0.0697 - val_loss: 8.1551 - val_digit1_loss: 4.1137 - val_digit2_loss: 4.0414 - val_digit1_accuracy: 0.0000e+00 - val_digit2_accuracy: 0.0192\n",
      "Epoch 2/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 6.4164 - digit1_loss: 3.1669 - digit2_loss: 3.2495 - digit1_accuracy: 0.1748 - digit2_accuracy: 0.1568 - val_loss: 7.9611 - val_digit1_loss: 3.9901 - val_digit2_loss: 3.9710 - val_digit1_accuracy: 0.0465 - val_digit2_accuracy: 0.0490\n",
      "Epoch 3/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 5.2195 - digit1_loss: 2.5511 - digit2_loss: 2.6684 - digit1_accuracy: 0.3038 - digit2_accuracy: 0.2801 - val_loss: 5.5803 - val_digit1_loss: 2.8081 - val_digit2_loss: 2.7723 - val_digit1_accuracy: 0.2148 - val_digit2_accuracy: 0.2145\n",
      "Epoch 4/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 4.1372 - digit1_loss: 2.0176 - digit2_loss: 2.1196 - digit1_accuracy: 0.4372 - digit2_accuracy: 0.4148 - val_loss: 4.2415 - val_digit1_loss: 2.2016 - val_digit2_loss: 2.0400 - val_digit1_accuracy: 0.3780 - val_digit2_accuracy: 0.4047\n",
      "Epoch 5/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 3.2014 - digit1_loss: 1.5409 - digit2_loss: 1.6604 - digit1_accuracy: 0.5639 - digit2_accuracy: 0.5348 - val_loss: 2.9322 - val_digit1_loss: 1.4435 - val_digit2_loss: 1.4888 - val_digit1_accuracy: 0.5698 - val_digit2_accuracy: 0.5803\n",
      "Epoch 6/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 2.5016 - digit1_loss: 1.1810 - digit2_loss: 1.3206 - digit1_accuracy: 0.6583 - digit2_accuracy: 0.6339 - val_loss: 2.4155 - val_digit1_loss: 1.2257 - val_digit2_loss: 1.1898 - val_digit1_accuracy: 0.6410 - val_digit2_accuracy: 0.6705\n",
      "Epoch 7/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 1.9524 - digit1_loss: 0.9014 - digit2_loss: 1.0510 - digit1_accuracy: 0.7407 - digit2_accuracy: 0.7114 - val_loss: 2.0572 - val_digit1_loss: 0.9912 - val_digit2_loss: 1.0660 - val_digit1_accuracy: 0.7067 - val_digit2_accuracy: 0.7067\n",
      "Epoch 8/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 1.5422 - digit1_loss: 0.7001 - digit2_loss: 0.8421 - digit1_accuracy: 0.7966 - digit2_accuracy: 0.7660 - val_loss: 1.6935 - val_digit1_loss: 0.8101 - val_digit2_loss: 0.8833 - val_digit1_accuracy: 0.7645 - val_digit2_accuracy: 0.7552\n",
      "Epoch 9/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 1.2501 - digit1_loss: 0.5544 - digit2_loss: 0.6956 - digit1_accuracy: 0.8364 - digit2_accuracy: 0.8047 - val_loss: 1.3984 - val_digit1_loss: 0.6440 - val_digit2_loss: 0.7545 - val_digit1_accuracy: 0.8185 - val_digit2_accuracy: 0.8027\n",
      "Epoch 10/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 1.0134 - digit1_loss: 0.4495 - digit2_loss: 0.5639 - digit1_accuracy: 0.8677 - digit2_accuracy: 0.8401 - val_loss: 1.3952 - val_digit1_loss: 0.6272 - val_digit2_loss: 0.7679 - val_digit1_accuracy: 0.8242 - val_digit2_accuracy: 0.7975\n",
      "Epoch 11/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.8331 - digit1_loss: 0.3692 - digit2_loss: 0.4639 - digit1_accuracy: 0.8898 - digit2_accuracy: 0.8679 - val_loss: 1.4344 - val_digit1_loss: 0.6579 - val_digit2_loss: 0.7765 - val_digit1_accuracy: 0.8065 - val_digit2_accuracy: 0.7900\n",
      "Epoch 12/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.6797 - digit1_loss: 0.2966 - digit2_loss: 0.3831 - digit1_accuracy: 0.9113 - digit2_accuracy: 0.8918 - val_loss: 1.3393 - val_digit1_loss: 0.6460 - val_digit2_loss: 0.6932 - val_digit1_accuracy: 0.8205 - val_digit2_accuracy: 0.8117\n",
      "Epoch 13/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.5787 - digit1_loss: 0.2428 - digit2_loss: 0.3360 - digit1_accuracy: 0.9266 - digit2_accuracy: 0.9051 - val_loss: 1.3769 - val_digit1_loss: 0.6971 - val_digit2_loss: 0.6797 - val_digit1_accuracy: 0.8043 - val_digit2_accuracy: 0.8067\n",
      "Epoch 14/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4838 - digit1_loss: 0.2128 - digit2_loss: 0.2710 - digit1_accuracy: 0.9380 - digit2_accuracy: 0.9233 - val_loss: 1.1521 - val_digit1_loss: 0.5731 - val_digit2_loss: 0.5789 - val_digit1_accuracy: 0.8413 - val_digit2_accuracy: 0.8480\n",
      "Epoch 15/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.4044 - digit1_loss: 0.1759 - digit2_loss: 0.2285 - digit1_accuracy: 0.9473 - digit2_accuracy: 0.9330 - val_loss: 1.1408 - val_digit1_loss: 0.5559 - val_digit2_loss: 0.5849 - val_digit1_accuracy: 0.8363 - val_digit2_accuracy: 0.8357\n",
      "Epoch 16/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3469 - digit1_loss: 0.1493 - digit2_loss: 0.1975 - digit1_accuracy: 0.9551 - digit2_accuracy: 0.9425 - val_loss: 1.2114 - val_digit1_loss: 0.5803 - val_digit2_loss: 0.6311 - val_digit1_accuracy: 0.8443 - val_digit2_accuracy: 0.8290\n",
      "Epoch 17/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.3019 - digit1_loss: 0.1356 - digit2_loss: 0.1664 - digit1_accuracy: 0.9611 - digit2_accuracy: 0.9513 - val_loss: 1.3380 - val_digit1_loss: 0.6655 - val_digit2_loss: 0.6725 - val_digit1_accuracy: 0.8332 - val_digit2_accuracy: 0.8248\n",
      "Epoch 18/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.2570 - digit1_loss: 0.1162 - digit2_loss: 0.1408 - digit1_accuracy: 0.9667 - digit2_accuracy: 0.9580 - val_loss: 0.8494 - val_digit1_loss: 0.3852 - val_digit2_loss: 0.4642 - val_digit1_accuracy: 0.9015 - val_digit2_accuracy: 0.8802\n",
      "Epoch 19/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.2224 - digit1_loss: 0.1013 - digit2_loss: 0.1211 - digit1_accuracy: 0.9688 - digit2_accuracy: 0.9657 - val_loss: 1.0689 - val_digit1_loss: 0.4831 - val_digit2_loss: 0.5858 - val_digit1_accuracy: 0.8683 - val_digit2_accuracy: 0.8518\n",
      "Epoch 20/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1999 - digit1_loss: 0.0859 - digit2_loss: 0.1141 - digit1_accuracy: 0.9762 - digit2_accuracy: 0.9672 - val_loss: 0.9422 - val_digit1_loss: 0.4416 - val_digit2_loss: 0.5006 - val_digit1_accuracy: 0.8750 - val_digit2_accuracy: 0.8618\n",
      "Epoch 21/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1736 - digit1_loss: 0.0784 - digit2_loss: 0.0951 - digit1_accuracy: 0.9777 - digit2_accuracy: 0.9712 - val_loss: 0.9381 - val_digit1_loss: 0.4628 - val_digit2_loss: 0.4752 - val_digit1_accuracy: 0.8765 - val_digit2_accuracy: 0.8770\n",
      "Epoch 22/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1579 - digit1_loss: 0.0707 - digit2_loss: 0.0872 - digit1_accuracy: 0.9796 - digit2_accuracy: 0.9746 - val_loss: 0.7438 - val_digit1_loss: 0.3355 - val_digit2_loss: 0.4083 - val_digit1_accuracy: 0.9105 - val_digit2_accuracy: 0.8980\n",
      "Epoch 23/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1340 - digit1_loss: 0.0597 - digit2_loss: 0.0743 - digit1_accuracy: 0.9821 - digit2_accuracy: 0.9790 - val_loss: 0.8802 - val_digit1_loss: 0.4217 - val_digit2_loss: 0.4585 - val_digit1_accuracy: 0.8978 - val_digit2_accuracy: 0.8765\n",
      "Epoch 24/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1284 - digit1_loss: 0.0601 - digit2_loss: 0.0683 - digit1_accuracy: 0.9826 - digit2_accuracy: 0.9809 - val_loss: 0.7773 - val_digit1_loss: 0.3602 - val_digit2_loss: 0.4170 - val_digit1_accuracy: 0.9110 - val_digit2_accuracy: 0.8982\n",
      "Epoch 25/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1191 - digit1_loss: 0.0557 - digit2_loss: 0.0635 - digit1_accuracy: 0.9831 - digit2_accuracy: 0.9818 - val_loss: 1.0088 - val_digit1_loss: 0.4936 - val_digit2_loss: 0.5152 - val_digit1_accuracy: 0.8920 - val_digit2_accuracy: 0.8725\n",
      "Epoch 26/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.1003 - digit1_loss: 0.0461 - digit2_loss: 0.0542 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9851 - val_loss: 0.8168 - val_digit1_loss: 0.4087 - val_digit2_loss: 0.4081 - val_digit1_accuracy: 0.8957 - val_digit2_accuracy: 0.8953\n",
      "Epoch 27/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0888 - digit1_loss: 0.0386 - digit2_loss: 0.0502 - digit1_accuracy: 0.9898 - digit2_accuracy: 0.9846 - val_loss: 1.0592 - val_digit1_loss: 0.5101 - val_digit2_loss: 0.5492 - val_digit1_accuracy: 0.8763 - val_digit2_accuracy: 0.8602\n",
      "Epoch 28/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0912 - digit1_loss: 0.0453 - digit2_loss: 0.0459 - digit1_accuracy: 0.9864 - digit2_accuracy: 0.9871 - val_loss: 0.9372 - val_digit1_loss: 0.4465 - val_digit2_loss: 0.4907 - val_digit1_accuracy: 0.8960 - val_digit2_accuracy: 0.8687\n",
      "Epoch 29/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0856 - digit1_loss: 0.0400 - digit2_loss: 0.0456 - digit1_accuracy: 0.9887 - digit2_accuracy: 0.9861 - val_loss: 0.7899 - val_digit1_loss: 0.3706 - val_digit2_loss: 0.4193 - val_digit1_accuracy: 0.9135 - val_digit2_accuracy: 0.9020\n",
      "Epoch 30/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0693 - digit1_loss: 0.0317 - digit2_loss: 0.0377 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9890 - val_loss: 1.2112 - val_digit1_loss: 0.5745 - val_digit2_loss: 0.6367 - val_digit1_accuracy: 0.8610 - val_digit2_accuracy: 0.8472\n",
      "Epoch 31/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0659 - digit1_loss: 0.0282 - digit2_loss: 0.0377 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9891 - val_loss: 0.6901 - val_digit1_loss: 0.3017 - val_digit2_loss: 0.3884 - val_digit1_accuracy: 0.9275 - val_digit2_accuracy: 0.9072\n",
      "Epoch 32/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0595 - digit1_loss: 0.0294 - digit2_loss: 0.0301 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9926 - val_loss: 0.8040 - val_digit1_loss: 0.3708 - val_digit2_loss: 0.4332 - val_digit1_accuracy: 0.9043 - val_digit2_accuracy: 0.8953\n",
      "Epoch 33/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0555 - digit1_loss: 0.0264 - digit2_loss: 0.0292 - digit1_accuracy: 0.9925 - digit2_accuracy: 0.9913 - val_loss: 0.7504 - val_digit1_loss: 0.3421 - val_digit2_loss: 0.4083 - val_digit1_accuracy: 0.9155 - val_digit2_accuracy: 0.8935\n",
      "Epoch 34/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0525 - digit1_loss: 0.0227 - digit2_loss: 0.0298 - digit1_accuracy: 0.9939 - digit2_accuracy: 0.9919 - val_loss: 0.6991 - val_digit1_loss: 0.3092 - val_digit2_loss: 0.3899 - val_digit1_accuracy: 0.9323 - val_digit2_accuracy: 0.9122\n",
      "Epoch 35/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0519 - digit1_loss: 0.0237 - digit2_loss: 0.0282 - digit1_accuracy: 0.9935 - digit2_accuracy: 0.9924 - val_loss: 0.7619 - val_digit1_loss: 0.3556 - val_digit2_loss: 0.4064 - val_digit1_accuracy: 0.9130 - val_digit2_accuracy: 0.9035\n",
      "Epoch 36/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0483 - digit1_loss: 0.0222 - digit2_loss: 0.0262 - digit1_accuracy: 0.9938 - digit2_accuracy: 0.9929 - val_loss: 0.7036 - val_digit1_loss: 0.3059 - val_digit2_loss: 0.3976 - val_digit1_accuracy: 0.9243 - val_digit2_accuracy: 0.9115\n",
      "Epoch 37/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0474 - digit1_loss: 0.0193 - digit2_loss: 0.0281 - digit1_accuracy: 0.9951 - digit2_accuracy: 0.9917 - val_loss: 0.7457 - val_digit1_loss: 0.3721 - val_digit2_loss: 0.3736 - val_digit1_accuracy: 0.9038 - val_digit2_accuracy: 0.9028\n",
      "Epoch 38/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0426 - digit1_loss: 0.0220 - digit2_loss: 0.0206 - digit1_accuracy: 0.9927 - digit2_accuracy: 0.9939 - val_loss: 0.7902 - val_digit1_loss: 0.3415 - val_digit2_loss: 0.4487 - val_digit1_accuracy: 0.9118 - val_digit2_accuracy: 0.8960\n",
      "Epoch 39/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0387 - digit1_loss: 0.0178 - digit2_loss: 0.0209 - digit1_accuracy: 0.9956 - digit2_accuracy: 0.9941 - val_loss: 0.6797 - val_digit1_loss: 0.3033 - val_digit2_loss: 0.3763 - val_digit1_accuracy: 0.9298 - val_digit2_accuracy: 0.9118\n",
      "Epoch 40/40\n",
      "160/160 [==============================] - 9s 56ms/step - loss: 0.0373 - digit1_loss: 0.0172 - digit2_loss: 0.0201 - digit1_accuracy: 0.9954 - digit2_accuracy: 0.9941 - val_loss: 0.7108 - val_digit1_loss: 0.3482 - val_digit2_loss: 0.3627 - val_digit1_accuracy: 0.9220 - val_digit2_accuracy: 0.9175\n"
     ]
    }
   ],
   "source": [
    "LETTERSTR = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "\n",
    "def toonehot(text):\n",
    "    labellist = []\n",
    "    for letter in text:\n",
    "        onehot = np.array([0 for _ in range(36)])\n",
    "        num = LETTERSTR.find(letter)\n",
    "        onehot[num] = 1\n",
    "        labellist.append(onehot)\n",
    "    return np.array(labellist)\n",
    "\n",
    "\n",
    "# Create CNN Model\n",
    "print(\"Creating CNN model...\")\n",
    "in_ = Input((100, 100, 3))\n",
    "out = in_\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Flatten()(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = [Dense(36, name='digit1', activation='softmax')(out),\\\n",
    "    Dense(36, name='digit2', activation='softmax')(out)]\n",
    "model = Model(inputs=in_, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "train_data = []\n",
    "train_label = [[] , []]\n",
    "path = 'captcha-hacker/train/task2'\n",
    "df = pd.read_csv('captcha-hacker/train/annotations.csv')\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img = image.load_img(os.path.join(path , filename) , target_size = (100 , 100))\n",
    "        aug_images = []\n",
    "        img = np.expand_dims(img , 0)\n",
    "        gen = ImageDataGenerator(\n",
    "        rotation_range = 10 , \n",
    "        width_shift_range = 0.15 , \n",
    "        height_shift_range = 0.15 , \n",
    "        shear_range = 0.15 , \n",
    "        zoom_range = 0.1 , \n",
    "        channel_shift_range = 10 , \n",
    "        )\n",
    "        aug_iter = gen.flow(img)\n",
    "        aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(8)]\n",
    "        label = df.loc[df['filename'] == os.path.join('task2' , filename) , 'label'].item()\n",
    "        label_ = toonehot(label)\n",
    "        for aug_pic in np.array(aug_images):\n",
    "            aug_pic = aug_pic.astype('float')/255.0\n",
    "            train_data.append(aug_pic)\n",
    "            for i in range(2):\n",
    "                train_label[i].append(label_[i])\n",
    "train_data = np.array(train_data)\n",
    "train_label = [arr for arr in np.asarray(train_label)]\n",
    "# print(train_data.shape)\n",
    "# print(train_label.shape)\n",
    "# train_data = tf.stack(train_data)\n",
    "# train_label = tf.stack(train_label)\n",
    "# print (train_data.shape)\n",
    "\n",
    "model.fit(train_data, train_label, batch_size = 100, epochs = 40, verbose=1 , validation_split=0.2) \n",
    "model.save(\"part2_model.h5\")         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd195debedd9f76abfb67120cba4d311fae7ef674e8e3c46884450cf5aef9627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
