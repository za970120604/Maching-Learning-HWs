{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoHhaKCzR7WP"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "import keras.utils as image\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "LETTERSTR = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "\n",
        "def toonehot(text):\n",
        "    labellist = []\n",
        "    for letter in text:\n",
        "        onehot = np.array([0 for _ in range(36)])\n",
        "        num = LETTERSTR.find(letter)\n",
        "        onehot[num] = 1\n",
        "        labellist.append(onehot)\n",
        "    return np.array(labellist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z0GS4OeR_Cy"
      },
      "outputs": [],
      "source": [
        "# Create CNN Model\n",
        "print(\"Creating CNN model...\")\n",
        "in_ = Input((72, 96, 3))\n",
        "out = in_\n",
        "out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
        "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
        "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
        "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
        "out = BatchNormalization()(out)\n",
        "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "out = Flatten()(out)\n",
        "out = Dropout(0.3)(out)\n",
        "out = [Dense(36, name='digit1', activation='softmax')(out),\\\n",
        "    Dense(36, name='digit2', activation='softmax')(out),\\\n",
        "    Dense(36, name='digit3', activation='softmax')(out),\\\n",
        "    Dense(36, name='digit4', activation='softmax')(out)]\n",
        "model = Model(inputs=in_, outputs=out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef6I8BT6SKKj"
      },
      "outputs": [],
      "source": [
        "train_data = []\n",
        "train_label = [[] , [] , [] , []]\n",
        "path = '/home/undergrad/.kaggle/train/task3'\n",
        "df = pd.read_csv('/home/undergrad/.kaggle/train/annotations.csv')\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "        img = image.load_img(os.path.join(path , filename) , target_size = (100 , 100))\n",
        "        aug_images = []\n",
        "        img = np.expand_dims(img , 0)\n",
        "        gen = ImageDataGenerator(\n",
        "        rotation_range = 10 , \n",
        "        width_shift_range = 0.15 , \n",
        "        height_shift_range = 0.15 , \n",
        "        shear_range = 0.15 , \n",
        "        zoom_range = 0.1 , \n",
        "        channel_shift_range = 10 , \n",
        "        )\n",
        "        aug_iter = gen.flow(img)\n",
        "        aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(20)]\n",
        "        label = df.loc[df['filename'] == os.path.join('task3' , filename) , 'label'].item()\n",
        "        label_ = toonehot(label)\n",
        "        for aug_pic in np.array(aug_images):\n",
        "            aug_pic = aug_pic.astype('float')/255.0\n",
        "            train_data.append(aug_pic)\n",
        "            for i in range(4):\n",
        "                train_label[i].append(label_[i])\n",
        "train_data = np.array(train_data)\n",
        "train_label = [arr for arr in np.asarray(train_label)]\n",
        "# print(train_data.shape)\n",
        "# print(train_label.shape)\n",
        "# train_data = tf.stack(train_data)\n",
        "# train_label = tf.stack(train_label)\n",
        "\n",
        "\n",
        "model.fit(train_data, train_label, batch_size = 400, epochs = 20, verbose=1 , validation_split=0.2) \n",
        "model.save(\"part3_model.h5\")         "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd195debedd9f76abfb67120cba4d311fae7ef674e8e3c46884450cf5aef9627"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
